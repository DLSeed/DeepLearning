{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLSeed/DeepLearning/blob/main/Sovits1_0%E4%B8%80%E9%94%AE%E5%90%88%E6%88%90%EF%BC%88%E5%81%9C%E6%AD%A2%E7%BB%B4%E6%8A%A4%EF%BC%8C%E4%BD%86%E6%98%AF%E5%8F%AF%E7%94%A8%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-IpF6c5X0q_"
      },
      "source": [
        "# 简介\n",
        "\n",
        "**请使用新脚本**\n",
        "\n",
        "**[sovits_f0一键合成](https://colab.research.google.com/drive/1F3VpHCi9eridGw1F1hbqR7qhXGKuSCus)**\n",
        "\n",
        "**新脚本配合新的模型**\n",
        "\n",
        "**此脚本配合旧模型及十人预模型**\n",
        "\n",
        "sovits包括**训练、合成**两部分，替换至本篇进行合成的模型必须是**Rcell版引入f0参数的sovits方式训练出的模型（三件套的colab，模型仅在内部互通）**\n",
        "\n",
        "**格式参考vits专栏三件套（评论区）**[vits注解](https://www.bilibili.com/read/cv18478187)\n",
        "\n",
        "95%的问题都可以参考专栏解决，剩下的我也不会了\n",
        "\n",
        "[一键制作数据集](https://colab.research.google.com/drive/1qzTZQp7ew7HMal4oApm4DI1cK2JR1N0t)\n",
        "\n",
        "[一键训练](https://colab.research.google.com/drive/1xTCtNOK0Rglzq06H3iAwBwVnBuz0fgxJ)\n",
        "\n",
        "**支持一键合成长时间的音频（5min以上），建议使用GPU（CPU比较慢）**\n",
        "\n",
        "按照[Rcell](https://space.bilibili.com/343303724)大佬的思路拼合soft-vc与vits，\n",
        "使用[Francis-Komizu](https://space.bilibili.com/636704927)大佬的原colab结构，并延续Sovits的称呼。\n",
        "\n",
        "hubert.pt为[soft-vc](https://github.com/bshall/hubert)发布的内容合成器模型，generator_idxr.pth为R佬在huggingface发布的模型；采用存在谷歌云盘的方式，节约下载时间。\n",
        "[Sovits](https://github.com/IceKyrin/Sovits) fork自F佬的[github](https://github.com/Francis-Komizu/Sovits)，其中内置了R佬pth的config.json及官方hubert模块（改为加载本地模型方式），以方便使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMIJduVhX2Ge"
      },
      "source": [
        "# 配置环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfuRLaqys47I"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/IceKyrin/sovits_infer_rcell\n",
        "%cd sovits_infer_rcell\n",
        "!pip install -r requirements.txt\n",
        "!mkdir pth\n",
        "!mkdir raw\n",
        "!mkdir results\n",
        "%cd wav_temp\n",
        "!mkdir input\n",
        "!mkdir output\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMUmOmIiX873"
      },
      "outputs": [],
      "source": [
        "!pip install pydub\n",
        "import os\n",
        "import shutil\n",
        "import utils\n",
        "import torch\n",
        "import hubert\n",
        "import librosa\n",
        "import logging\n",
        "import soundfile\n",
        "import torchcrepe\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from wav_temp import merge\n",
        "from models import SynthesizerTrn\n",
        "from text.symbols import symbols\n",
        "from text import text_to_sequence\n",
        "from pydub import AudioSegment\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "\n",
        "# python删除文件的方法 os.remove(path)path指的是文件的绝对路径,如：\n",
        "def del_file(path_data):\n",
        "    for i in os.listdir(path_data):  # os.listdir(path_data)#返回一个列表，里面是当前目录下面的所有东西的相对路径\n",
        "        os.remove(path_data + i)\n",
        "\n",
        "\n",
        "def cut(cut_time, file_path, vocal_name, out_dir):\n",
        "    audio_segment = AudioSegment.from_file(file_path, format='wav')\n",
        "\n",
        "    total = int(audio_segment.duration_seconds / cut_time)  # 计算音频切片后的个数\n",
        "    for i in range(total):\n",
        "        # 将音频10s切片，并以顺序进行命名\n",
        "        audio_segment[i * cut_time * 1000:(i + 1) * cut_time * 1000].export(f\"{out_dir}/{vocal_name}-{i}.wav\",\n",
        "                                                                            format=\"wav\")\n",
        "    audio_segment[total * cut_time * 1000:].export(f\"{out_dir}/{vocal_name}-{total}.wav\", format=\"wav\")  # 缺少结尾的音频片段\n",
        "\n",
        "\n",
        "def resample_to_22050(audio_path):\n",
        "    raw_audio, raw_sample_rate = torchaudio.load(audio_path)\n",
        "    audio_22050 = torchaudio.transforms.Resample(orig_freq=raw_sample_rate, new_freq=22050)(raw_audio)[0]\n",
        "    soundfile.write(audio_path, audio_22050, 22050)\n",
        "\n",
        "\n",
        "def get_text(text, hps):\n",
        "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
        "    if hps.data.add_blank:\n",
        "        text_norm = commons.intersperse(text_norm, 0)\n",
        "    text_norm = torch.LongTensor(text_norm)\n",
        "    return text_norm\n",
        "\n",
        "\n",
        "def resize2d(source, target_len):\n",
        "    source[source < 0.001] = np.nan\n",
        "    target = np.interp(np.arange(0, len(source) * target_len, len(source)) / target_len, np.arange(0, len(source)),\n",
        "                       source)\n",
        "    return np.nan_to_num(target)\n",
        "\n",
        "\n",
        "def convert_wav_22050_to_f0():\n",
        "    if torch.cuda.is_available():\n",
        "        audio, sr = torchcrepe.load.audio(source_path)\n",
        "        tmp = torchcrepe.predict(audio=audio, fmin=50, fmax=550,\n",
        "                                 sample_rate=22050, model='full',\n",
        "                                 batch_size=2048, device='cuda:0').numpy()[0]\n",
        "    else:\n",
        "        tmp = librosa.pyin(librosa.load(source_path)[0],\n",
        "                           fmin=librosa.note_to_hz('C2'),\n",
        "                           fmax=librosa.note_to_hz('C7'),\n",
        "                           frame_length=1780)[0]\n",
        "    f0 = np.zeros_like(tmp)\n",
        "    f0[tmp > 0] = tmp[tmp > 0]\n",
        "    return f0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "monWsXd-YUUb"
      },
      "source": [
        "# 加载模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiHW39jFYhou"
      },
      "source": [
        "## 加载内容编码器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ2mXdCa10di"
      },
      "outputs": [],
      "source": [
        "# 这个东西是https://github.com/bshall/hubert/releases/tag/v0.1 的hubert-soft-0d54a1f4.pt，可以自己替换来源、但是不能换其他模型（路径自己改）。\n",
        "!gdown --id '1cA37nsiSnsouF2TJkaXb3_VoA-rbifTu' --output /content/sovits_infer_rcell/pth/hubert.pt\n",
        "hubert_soft = hubert.hubert_soft('/content/sovits_infer_rcell/pth/hubert.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C5qnjljYoPX"
      },
      "source": [
        "## 加载生成器"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果要**替换自己的模型**，将 !gdown这行注释掉（行首加个“#”即可，注释成功则变绿）\n",
        "\n",
        "将**自己的配置json（上一篇生成了的）**上传至/content/sovits_infer_rcell/configs/文件夹\n",
        "将**自己的模型（上一篇生成了的）**上传至/content/sovits_infer_rcell/pth文件夹"
      ],
      "metadata": {
        "id": "rEXBSUEwtu6U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNtmkYruYVqL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "#@markdown 是否使用谷歌盘内模型（不勾选则自动下载十人预模型/猫雷）\n",
        "g_drive = False #@param {type:\"boolean\"}\n",
        "if g_drive:\n",
        "  drive.mount('/content/drive/')\n",
        "  config_path = \"./configs/maolei.json\" #@param {type:\"string\"}\n",
        "  model_path = '/content/drive/MyDrive/paimeng/G.pth' #@param {type:\"string\"}\n",
        "else:\n",
        "  #@markdown 是否使用十人预模型（不勾选则自动下载猫雷）\n",
        "  pre_pth = False #@param {type:\"boolean\"}\n",
        "  if pre_pth:\n",
        "    !gdown --id '18AjNe4ICb4esodRsLsnWd5Je7rUcHK-h' --output /content/sovits_infer_rcell/pth/G.pth\n",
        "    config_path = \"./configs/lang_pre.json\"\n",
        "  else:\n",
        "    # 这个东西是https://huggingface.co/spaces/innnky/soft-vits-singingvc 的G.pth（猫雷），可以换成自己的模型（必须是按照sovits方式训练出的其他角色模型）\n",
        "    !gdown --id '1gg1Igsa7nOtsLohtv-hNq2mmXCsbFqZJ' --output /content/sovits_infer_rcell/pth/G.pth\n",
        "    config_path = \"./configs/vctk_base.json\"\n",
        "  model_path = \"/content/sovits_infer_rcell/pth/G.pth\"\n",
        "\n",
        "hps_ms = utils.get_hparams_from_file(config_path)\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net_g_ms = SynthesizerTrn(\n",
        "    len(symbols),\n",
        "    hps_ms.data.filter_length // 2 + 1,\n",
        "    hps_ms.train.segment_size // hps_ms.data.hop_length,\n",
        "    n_speakers=hps_ms.data.n_speakers,\n",
        "    **hps_ms.model)\n",
        "_ = utils.load_checkpoint(model_path, net_g_ms, None)\n",
        "_ = net_g_ms.eval().to(dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy-GDKKsZl-j"
      },
      "source": [
        "# 声音转换\n",
        "\n",
        "支持{1、2}**任选一个方式**的声音转换！\n",
        "支持**10s以上5分钟以内**的音频（再久合成时间会过长）。\n",
        "上传到/content/sovits_infer_rcell/raw文件夹，支持自动合成歌曲\n",
        "\n",
        "使用[spleeter](https://github.com/deezer/spleeter)的2stems模式分离歌曲，自动生成这两个文件。（请自行阅读官方使用文档）\n",
        "\n",
        "spleeter separate -p spleeter:2stems -o output audio_example.mp3\n",
        "\n",
        "**结果自动输出至results文件夹。**自行下载，无预览\n",
        "mp3为自动合成的带伴奏歌曲，out_vits为纯人声。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "跑调破音基本是因为直播采样到的音域不够，这个没办法。（狗头）猫雷高音上不去、低音下不去。\n",
        "例子是牵丝戏，可以不下。明显感觉开头的低音、戏腔都炸了，其他部分还好。"
      ],
      "metadata": {
        "id": "YIYXbcATPaXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 进results下载试听\n",
        "!gdown --id '1ymJDK1VSESzv2xv_2Ce8h4QoSnzoplt7' --output /content/sovits_infer_rcell/results/demo.mp3"
      ],
      "metadata": {
        "id": "XbBW_XMOQKYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqCACnGFbOZE"
      },
      "source": [
        "1、使用参考音频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX_Rgrc6iQtt"
      },
      "outputs": [],
      "source": [
        "!gdown --id '10JQMPdzp0gjg9cVVersxVZWhIr4UwrFF' --output /content/sovits_infer_rcell/raw/vocals.wav\n",
        "!gdown --id '1lwmw9P-kgNYjjUveD8J_HuF_yfcdnoHJ' --output /content/sovits_infer_rcell/raw/bgm.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmYTeL_BiXty"
      },
      "source": [
        "2、使用上传音频\n",
        "\n",
        "自行上传至raw文件夹（单声道，22050hz，wav格式），可有bgm.wav（必须为wav格式），无伴奏则为纯人声合成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wHXCofJ_64b"
      },
      "source": [
        "3、合成音频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXoalx7B2NEv"
      },
      "outputs": [],
      "source": [
        "#@markdown **单声道，22050hz，wav格式**\n",
        "\n",
        "#@markdown 角色id——猫雷模型：0号为猫雷\n",
        "\n",
        "#@markdown 预模型——音色列表：（即霜效果较好）\n",
        "\n",
        "#@markdown 0、辉宇·星  1、星羽、光  2、opencpop中文歌声公开数据集  3、jsut日语公开数据集\n",
        "\n",
        "#@markdown 4、崇山悟  5、奕兰秋  6、云灏  7、遂安  8、即霜  9、雯喣\n",
        "\n",
        "#@markdown 角色id\n",
        "speaker_id = \"0\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown 人声文件名（不带.wav）\n",
        "clean_name = \"vocals\" #@param {type:\"string\"}\n",
        "#@markdown 伴奏文件名（可以不放伴奏）（不带.wav）\n",
        "bgm_name = \"bgm\" #@param {type:\"string\"}\n",
        "#@markdown 每次处理的长度，建议30s以内，大了炸显存\n",
        "cut_time = \"30\" #@param {type:\"string\"}\n",
        "#@markdown 变音高，一般不动\n",
        "vc_transform = 1 #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "out_audio_name = clean_name\n",
        "\n",
        "resample_to_22050(f'./raw/{clean_name}.wav')\n",
        "del_file(\"./wav_temp/input/\")\n",
        "del_file(\"./wav_temp/output/\")\n",
        "\n",
        "raw_audio_path = f\"./raw/{clean_name}.wav\"\n",
        "\n",
        "audio, sample_rate = torchaudio.load(raw_audio_path)\n",
        "\n",
        "audio_time = audio.shape[-1] / 22050\n",
        "if audio_time > 1.3 * int(cut_time):\n",
        "    cut(int(cut_time), raw_audio_path, clean_name, \"./wav_temp/input\")\n",
        "else:\n",
        "    shutil.copy(f\"./raw/{clean_name}.wav\", f\"./wav_temp/input/{clean_name}-0.wav\")\n",
        "file_list = os.listdir(\"./wav_temp/input\")\n",
        "\n",
        "count = 0\n",
        "for file_name in file_list:\n",
        "    source_path = \"./wav_temp/input/\" + file_name\n",
        "    vc_transform = 1\n",
        "    audio, sample_rate = torchaudio.load(source_path)\n",
        "    input_size = audio.shape[-1]\n",
        "    if sample_rate != 16000:\n",
        "        audio = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(audio)[0]\n",
        "    audio22050 = torchaudio.transforms.Resample(orig_freq=16000, new_freq=22050)(audio)[0]\n",
        "\n",
        "    # 此版本使用torchcrepe加速获取f0\n",
        "    f0 = convert_wav_22050_to_f0()\n",
        "\n",
        "    source = torch.FloatTensor(audio).unsqueeze(0).unsqueeze(0)\n",
        "    with torch.inference_mode():\n",
        "        units = hubert_soft.units(source)\n",
        "        soft = units.squeeze(0).cpu().numpy()\n",
        "        f0 = resize2d(f0, len(soft[:, 0])) * int(vc_transform)\n",
        "        soft[:, 0] = f0 / 10\n",
        "\n",
        "    sid = torch.LongTensor([int(speaker_id)]).to(dev)\n",
        "    stn_tst = torch.FloatTensor(soft)\n",
        "    x_tst = stn_tst.to(dev).unsqueeze(0)\n",
        "    x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(dev)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        audio = net_g_ms.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=0, noise_scale_w=0, length_scale=1)[0][\n",
        "            0, 0].data.cpu().float().numpy()\n",
        "    soundfile.write(\"./wav_temp/output/\" + file_name, audio, int(audio.shape[0] / input_size * 22050))\n",
        "    count += 1\n",
        "    print(\"%s success: %.2f%%\" % (file_name, 100 * count / len(file_list)))\n",
        "merge.run(clean_name, bgm_name, out_audio_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "import torchaudio\n",
        "#@markdown 预览干声（自行进results查看文件名，带.wav，仅支持wav）\n",
        "source_path = \"/content/sovits_infer_rcell/results/vocals.wav\"  #@param {type:\"string\"}\n",
        "audio,sr = torchaudio.load(source_path)\n",
        "ipd.display(ipd.Audio(audio, rate=sr))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vjkgBV7j2cVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi1ajEiZftyN"
      },
      "source": [
        "# 参考\n",
        "\n",
        "https://github.com/bshall/soft-vc\n",
        "\n",
        "[基于VITS和SoftVC实现任意对一VoiceConversion](https://www.bilibili.com/video/BV1S14y1x78X?share_source=copy_web&vd_source=630b87174c967a898cae3765fba3bfa8)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "742fb0cf312e06021cb7ef6febc33961079fd3903e709e6dbd223a75c181bd01"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}