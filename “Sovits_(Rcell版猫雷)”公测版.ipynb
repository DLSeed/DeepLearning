{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLSeed/DeepLearning/blob/main/%E2%80%9CSovits_(Rcell%E7%89%88%E7%8C%AB%E9%9B%B7)%E2%80%9D%E5%85%AC%E6%B5%8B%E7%89%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-IpF6c5X0q_"
      },
      "source": [
        "# 简介\n",
        "按照[Rcell](https://space.bilibili.com/343303724)大佬的思路拼合soft-vc与vits，\n",
        "使用[Francis-Komizu](https://space.bilibili.com/636704927)大佬的原colab结构，并延续Sovits的称呼。\n",
        "\n",
        "R佬合成音频时使用librosa模块取f0、效率略低，以torchcrepe模块代替，合成音频步骤节约了30%的时间。\n",
        "\n",
        "hubert.pt为[soft-vc](https://github.com/bshall/hubert)发布的内容合成器模型，generator_idxr.pth为R佬在huggingface发布的模型；采用存在谷歌云盘的方式，节约下载时间。\n",
        "[Sovits](https://github.com/IceKyrin/Sovits) fork自F佬的[github](https://github.com/Francis-Komizu/Sovits)，其中内置了R佬pth的config.json及官方hubert模块（改为加载本地模型方式），以方便使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMIJduVhX2Ge"
      },
      "source": [
        "# 配置环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfuRLaqys47I"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/IceKyrin/Sovits\n",
        "%cd Sovits\n",
        "!pip install -r requirements.txt\n",
        "!pip install torchcrepe\n",
        "%cd monotonic_align\n",
        "!python setup.py build_ext --inplace\n",
        "%cd ..\n",
        "!mkdir results\n",
        "!mkdir uploadings\n",
        "!mkdir recordings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMUmOmIiX873"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "import torchaudio\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import commons\n",
        "import utils\n",
        "from data_utils import UnitAudioLoader, UnitAudioCollate\n",
        "from models import SynthesizerTrn\n",
        "import requests\n",
        "\n",
        "from scipy.io.wavfile import write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "monWsXd-YUUb"
      },
      "source": [
        "# 加载模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiHW39jFYhou"
      },
      "source": [
        "## 加载内容编码器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ2mXdCa10di"
      },
      "outputs": [],
      "source": [
        "import hubert\n",
        "!gdown --id '1cA37nsiSnsouF2TJkaXb3_VoA-rbifTu' --output /content/Sovits/hubert/hubert.pt\n",
        "hubert_soft = hubert.hubert_soft('/content/Sovits/hubert/hubert.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C5qnjljYoPX"
      },
      "source": [
        "## 加载生成器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNtmkYruYVqL"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import torch\n",
        "\n",
        "import commons\n",
        "import utils\n",
        "from models import SynthesizerTrn\n",
        "from text.symbols import symbols\n",
        "\n",
        "!gdown --id '1gg1Igsa7nOtsLohtv-hNq2mmXCsbFqZJ' --output generator_idxr.pth\n",
        "\n",
        "hps = utils.get_hparams_from_file(\"/content/Sovits/configs/ljs_base.json\")\n",
        "hps_ms = utils.get_hparams_from_file(\"/content/Sovits/configs/vctk_base.json\")\n",
        "net_g_ms = SynthesizerTrn(\n",
        "    # len(symbols),\n",
        "    hps_ms.data.filter_length // 2 + 1,\n",
        "    hps_ms.train.segment_size // hps.data.hop_length,\n",
        "    n_speakers=hps_ms.data.n_speakers,\n",
        "    **hps_ms.model)\n",
        "_ = utils.load_checkpoint(\"generator_idxr.pth\", net_g_ms, None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy-GDKKsZl-j"
      },
      "source": [
        "# 声音转换\n",
        "\n",
        "支持{1、2}**任选一个方式**的声音转换！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqCACnGFbOZE"
      },
      "source": [
        "1、使用参考音频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX_Rgrc6iQtt"
      },
      "outputs": [],
      "source": [
        "# 任选一个demo\n",
        "!gdown --id '1p-LO3kG7E6VpY-p-2-AgRmkiJWYFDC8V' --output demo.wav\n",
        "# !gdown --id '10JQMPdzp0gjg9cVVersxVZWhIr4UwrFF' --output demo.wav\n",
        "\n",
        "source_path = 'demo.wav'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmYTeL_BiXty"
      },
      "source": [
        "2、使用上传音频（建议30s以内，单声道，22050hz，格式不符可能出bug）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlpqZZE8iJjr"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "uploaded = files.upload()\n",
        "old_path = list(uploaded.keys())[0]\n",
        "new_path = f'uploadings/{old_path}'\n",
        "shutil.move(old_path, new_path)\n",
        "source_path = new_path\n",
        "\n",
        "source, sr = torchaudio.load(source_path)\n",
        "source = torchaudio.functional.resample(source, sr, 22050)\n",
        "source = source.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wHXCofJ_64b"
      },
      "source": [
        "3、合成音频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXoalx7B2NEv"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import torchcrepe\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "def resize2d(source, target_len):\n",
        "    source[source<0.001] = np.nan\n",
        "    target = np.interp(np.arange(0, len(source), len(source) / target_len), np.arange(0, len(source)), source)\n",
        "    return np.nan_to_num(target)\n",
        "def convert_wav_22050_to_f0(audio):\n",
        "    tmp = librosa.pyin(audio,\n",
        "                fmin=librosa.note_to_hz('C0'),\n",
        "                fmax=librosa.note_to_hz('C7'),\n",
        "                frame_length=1780)[0]\n",
        "    print(tmp)\n",
        "    f0 = np.zeros_like(tmp)\n",
        "    f0[tmp>0] = tmp[tmp>0]\n",
        "    return f0\n",
        "\n",
        "def convert_wav_22050_to_f1(audio):\n",
        "    audio, sr = torchcrepe.load.audio(source_path)\n",
        "    tmp = torchcrepe.predict(audio=audio,\n",
        "                  fmin=50,\n",
        "                  fmax=550,\n",
        "                  sample_rate=22050,\n",
        "                  model='full',\n",
        "                  batch_size=1780, device='cuda:0').numpy()[0]\n",
        "    # print(tmp)\n",
        "    f0 = np.zeros_like(tmp)\n",
        "    f0[tmp > 0] = tmp[tmp > 0]\n",
        "    return f0\n",
        "\n",
        "\n",
        "# 原版\n",
        "r_source, r_sr = torchaudio.load(source_path)\n",
        "r_resampler = torchaudio.transforms.Resample(r_sr, 22050)\n",
        "r_source = r_resampler(r_source)\n",
        "r_source = r_source.unsqueeze(0)\n",
        "\n",
        "\n",
        "vc_transform = 1\n",
        "\n",
        "audio, sampling_rate = soundfile.read(source_path)\n",
        "if sampling_rate != 16000:\n",
        "  audio = librosa.resample(audio, orig_sr=sampling_rate, target_sr=16000)\n",
        "\n",
        "audio22050 = librosa.resample(audio, orig_sr=16000, target_sr=22050)\n",
        "\n",
        "# 改此函数可切换回Rcell原版，此版本使用torchcrepe加速获取f0\n",
        "f0 = convert_wav_22050_to_f1(audio22050)\n",
        "# f0 = convert_wav_22050_to_f0(audio22050)\n",
        "\n",
        "source = torch.FloatTensor(audio).unsqueeze(0).unsqueeze(0)\n",
        "print(source.shape)\n",
        "with torch.inference_mode():\n",
        "    units = hubert_soft.units(source)\n",
        "    soft = units.squeeze(0).numpy()\n",
        "    print(sampling_rate)\n",
        "    f0 = resize2d(f0, len(soft[:, 0])) * vc_transform\n",
        "    soft[:, 0] = f0 / 10\n",
        "sid = torch.LongTensor([0])\n",
        "stn_tst = torch.FloatTensor(soft)\n",
        "with torch.no_grad():\n",
        "    x_tst = stn_tst.unsqueeze(0)\n",
        "    x_tst_lengths = torch.LongTensor([stn_tst.size(0)])\n",
        "    audio = net_g_ms.infer(x_tst, x_tst_lengths,sid=sid, noise_scale=0, noise_scale_w=0, length_scale=1)[0][\n",
        "        0, 0].data.float().numpy()\n",
        "print(\"Source:\")\n",
        "ipd.display(ipd.Audio(r_source.squeeze(), rate=r_sr))\n",
        "print(\"Converted:\")\n",
        "ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GawX-3JldsNJ"
      },
      "source": [
        "### 保存\n",
        "\n",
        "为生合成的语音设定一个文件名。注意不需要加扩展名！\n",
        "\n",
        "命名后运行该代码块，你将在左侧文件系统中`/content/Sovits/results/`文件夹中找到它！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDkcn58UeHqj"
      },
      "outputs": [],
      "source": [
        "filename = 'natsume' #@param {type: \"string\"}\n",
        "audio_path = f'/content/Sovits/results/{filename}.wav'\n",
        "write(audio_path, 22050, audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi1ajEiZftyN"
      },
      "source": [
        "# 参考\n",
        "\n",
        "https://github.com/bshall/soft-vc\n",
        "\n",
        "[基于VITS和SoftVC实现任意对一VoiceConversion](https://www.bilibili.com/video/BV1S14y1x78X?share_source=copy_web&vd_source=630b87174c967a898cae3765fba3bfa8)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "742fb0cf312e06021cb7ef6febc33961079fd3903e709e6dbd223a75c181bd01"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}